{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define Problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Titanic what sorts of people were likely to survive. \n",
    "Apply the tools of machine learning to predict which passengers survived the tragedy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Collecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download them on Kaggle (train.csv, test.csv, gender_submission.csv) https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load train, test dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "training = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "\n",
    "training['train_test'] = 1\n",
    "test['train_test'] = 0\n",
    "test['Survived'] = np.NaN\n",
    "all_data = pd.concat([training,test])\n",
    "\n",
    "%matplotlib inline\n",
    "all_data.columns\n",
    "\n",
    "training.info()\n",
    "\n",
    "#to better understand the numeric data \n",
    "#(gives us an understanding of the central tendecies of data)\n",
    "training.describe()\n",
    "\n",
    "#quick way to separate numeric columns\n",
    "training.describe().columns\n",
    "\n",
    "# look at numeric and categorical values separately \n",
    "df_num = training[['Age','SibSp','Parch','Fare']] #Histogram \n",
    "df_cat = training[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']] #Value Counts\n",
    "\n",
    "#distributions for all numeric variables \n",
    "for i in df_num.columns:\n",
    "    plt.hist(df_num[i])\n",
    "    plt.title(i)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "#Looking at data noramalize and scale data that is not distrubuted. \n",
    "# All of them besides Age \n",
    "    \n",
    "print(df_num.corr())\n",
    "sns.heatmap(df_num.corr())\n",
    "\n",
    "#Helps us understand the correlation for data\n",
    "# If using regression avoid multicollinearity \n",
    "#(two variables highly correlated has a effect on model) \n",
    "\n",
    "# compare survival rate across Age, SibSp, Parch, and Fare \n",
    "pd.pivot_table(training, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])\n",
    "\n",
    "# Take note of data above\n",
    "\n",
    "for i in df_cat.columns:\n",
    "    sns.barplot(df_cat[i].value_counts().index,df_cat[i].value_counts()).set_title(i)\n",
    "    plt.show()\\\n",
    "    \n",
    "# Comparing survival and each of these categorical variables \n",
    "print(pd.pivot_table(training, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))\n",
    "print()\n",
    "print(pd.pivot_table(training, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))\n",
    "print()\n",
    "print(pd.pivot_table(training, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))\n",
    "\n",
    "#Piviot table for each data so we can compare to dependent variable survive or not  (above)\n",
    "\n",
    "#Feature Engineering (Seperate cabins, letter of cabin (same location))\n",
    "#List questions here\n",
    "\n",
    "pd.pivot_table(training, index = 'Survived', columns = 'cabin_multiple', values = 'Ticket' ,aggfunc ='count')\n",
    "\n",
    "#creates categories based on the cabin letter (n stands for null)\n",
    "#in this case we will treat null values like it's own category\n",
    "\n",
    "training['cabin_adv'] = training.Cabin.apply(lambda x: str(x)[0])\n",
    "\n",
    "#comparing surivial rate by cabin\n",
    "print(training.cabin_adv.value_counts())\n",
    "pd.pivot_table(training,index='Survived',columns='cabin_adv', values = 'Name', aggfunc='count')\n",
    "\n",
    "#understand ticket values better \n",
    "#numeric vs non numeric \n",
    "training['numeric_ticket'] = training.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "training['ticket_letters'] = training.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\n",
    "# Letters on tickets?\n",
    "\n",
    "training['numeric_ticket'].value_counts()\n",
    "\n",
    "\n",
    "#lets us view all rows in dataframe through scrolling. This is for convenience \n",
    "pd.set_option(\"max_rows\", None)\n",
    "training['ticket_letters'].value_counts()\n",
    "\n",
    "#did not understand what the letters are for on the tickets\n",
    "\n",
    "#difference in numeric vs non-numeric tickets in survival rate \n",
    "pd.pivot_table(training,index='Survived',columns='numeric_ticket', values = 'Ticket', aggfunc='count')\n",
    "\n",
    "#no correlation (expermential)  \n",
    "\n",
    "#survival rate across different tyicket types \n",
    "pd.pivot_table(training,index='Survived',columns='ticket_letters', values = 'Ticket', aggfunc='count')\n",
    "\n",
    "#feature engineering on person's title \n",
    "training.Name.head(50)\n",
    "training['name_title'] = training.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "#mr., ms., master. etc\n",
    " \n",
    "training['name_title'].value_counts()\n",
    "\n",
    "# very small samples higher title maybe higher chance of surivival \n",
    "\n",
    "# Orgnaizing data for model, getting ride of null values\n",
    "\n",
    "#Not good a practice in data science train a one on coder, \n",
    "# train a scaler only on the training data, then transform test data, \n",
    "# then using encoder only on train data, must ensure that distributions are very similar  \n",
    "\n",
    "#Data Preprocessing for Model\n",
    "#List questions\n",
    "\n",
    "#create all categorical variables that we did above for both training and test sets \n",
    "all_data['cabin_multiple'] = all_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\n",
    "all_data['cabin_adv'] = all_data.Cabin.apply(lambda x: str(x)[0])\n",
    "all_data['numeric_ticket'] = all_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "all_data['ticket_letters'] = all_data.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\n",
    "all_data['name_title'] = all_data.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "#impute nulls for continuous data \n",
    "#all_data.Age = all_data.Age.fillna(training.Age.mean())\n",
    "all_data.Age = all_data.Age.fillna(training.Age.median())\n",
    "#all_data.Fare = all_data.Fare.fillna(training.Fare.mean())\n",
    "all_data.Fare = all_data.Fare.fillna(training.Fare.median())\n",
    "\n",
    "#drop null 'embarked' rows. Only 2 instances of this in training and 0 in test \n",
    "all_data.dropna(subset=['Embarked'],inplace = True)\n",
    "\n",
    "#tried log norm of sibsp (not used)\n",
    "all_data['norm_sibsp'] = np.log(all_data.SibSp+1)\n",
    "all_data['norm_sibsp'].hist()\n",
    "\n",
    "# log norm of fare (used)\n",
    "all_data['norm_fare'] = np.log(all_data.Fare+1)\n",
    "all_data['norm_fare'].hist()\n",
    "\n",
    "# converted fare to category for pd.get_dummies()\n",
    "all_data.Pclass = all_data.Pclass.astype(str)\n",
    "\n",
    "#created dummy variables from categories (also can use OneHotEncoder)\n",
    "all_dummies = pd.get_dummies(all_data[['Pclass','Sex','Age','SibSp','Parch','norm_fare','Embarked','cabin_adv','cabin_multiple','numeric_ticket','name_title','train_test']])\n",
    "\n",
    "#Split to train test again\n",
    "X_train = all_dummies[all_dummies.train_test == 1].drop(['train_test'], axis =1)\n",
    "\n",
    "\n",
    "# Scale data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "all_dummies_scaled = all_dummies.copy()\n",
    "all_dummies_scaled[['Age','SibSp','Parch','norm_fare']]= scale.fit_transform(all_dummies_scaled[['Age','SibSp','Parch','norm_fare']])\n",
    "all_dummies_scaled\n",
    "\n",
    "X_train_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 1].drop(['train_test'], axis =1)\n",
    "X_test_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 0].drop(['train_test'], axis =1)\n",
    "\n",
    "y_train = all_data[all_data.train_test==1].Survived\n",
    "X_test = all_dummies[all_dummies.train_test == 0].drop(['train_test'], axis =1)\n",
    "\n",
    "\n",
    "y_train = all_data[all_data.train_test==1].Survived\n",
    "y_train.shape\n",
    "\n",
    "#Model Building (Baseline Validation Performance)\n",
    "# experiment with different models. Which one is the best?\n",
    "# uses cross validation 1st without tuning parameter then tune\n",
    "# know what data can go with what model\n",
    "# Naive Bayes (72.6%)\n",
    "# Logistic Regression (82.1%)\n",
    "# Decision Tree (77.6%)\n",
    "# K Nearest Neighbor (80.5%)\n",
    "# Random Forest (80.6%)\n",
    "# Support Vector Classifier (83.2%) <--------Highest %\n",
    "# Xtreme Gradient Boosting (81.8%)\n",
    "# Soft Voting Classifier - All Models (82.8%)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#I usually use Naive Bayes as a baseline for my classification tasks \n",
    "gnb = GaussianNB()\n",
    "cv = cross_val_score(gnb,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "lr = LogisticRegression(max_iter = 2000)\n",
    "cv = cross_val_score(lr,X_train,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "lr = LogisticRegression(max_iter = 2000)\n",
    "cv = cross_val_score(lr,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt,X_train,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn,X_train,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 1)\n",
    "cv = cross_val_score(rf,X_train,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 1)\n",
    "cv = cross_val_score(rf,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "svc = SVC(probability = True)\n",
    "cv = cross_val_score(svc,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state =1)\n",
    "cv = cross_val_score(xgb,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "#Voting classifier takes all of the inputs and averages the results. For a \"hard\" voting classifier each classifier gets 1 vote \"yes\" or \"no\" and the result is just a popular vote. For this, you generally want odd numbers\n",
    "#A \"soft\" classifier averages the confidence of each of the models. If a the average confidence is > 50% that it is a 1 it will be counted as such\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators = [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),('svc',svc),('xgb',xgb)], voting = 'soft') \n",
    "\n",
    "cv = cross_val_score(voting_clf,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "# Votting classifiers: take a bunch of different classifiers \n",
    "# they vote on wether or not a person surives or not \n",
    "# (helps normalize your result and generalize the data)\n",
    "# ensemble approaches: Random forests actually boost are ready in samba \n",
    "# (really powerful techinquies for solving problems) Good practice when not using deep learning\n",
    "#Model Tuned Performance\n",
    "# test the train data the high % could mean overtraining\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "\n",
    "#simple performance reporting function\n",
    "def clf_performance(classifier, model_name):\n",
    "    print(model_name)\n",
    "    print('Best Score: ' + str(classifier.best_score_))\n",
    "    print('Best Parameters: ' + str(classifier.best_params_))\n",
    "    \n",
    "lr = LogisticRegression()\n",
    "param_grid = {'max_iter' : [2000],\n",
    "              'penalty' : ['l1', 'l2'],\n",
    "              'C' : np.logspace(-4, 4, 20),\n",
    "              'solver' : ['liblinear']}\n",
    "\n",
    "clf_lr = GridSearchCV(lr, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_lr = clf_lr.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_lr,'Logistic Regression')\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors' : [3,5,7,9],\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n",
    "              'p' : [1,2]}\n",
    "clf_knn = GridSearchCV(knn, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_knn = clf_knn.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_knn,'KNN')\n",
    "\n",
    "\n",
    "svc = SVC(probability = True)\n",
    "param_grid = tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1,.5,1,2,5,10],\n",
    "                                  'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'kernel': ['linear'], 'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'kernel': ['poly'], 'degree' : [2,3,4,5], 'C': [.1, 1, 10, 100, 1000]}]\n",
    "clf_svc = GridSearchCV(svc, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_svc = clf_svc.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_svc,'SVC')\n",
    "\n",
    "#Because the total feature space is so large, I used a randomized search to narrow down the paramters for the model. I took the best model from this and did a more granular search \n",
    "\"\"\"\n",
    "rf = RandomForestClassifier(random_state = 1)\n",
    "param_grid =  {'n_estimators': [100,500,1000], \n",
    "                                  'bootstrap': [True,False],\n",
    "                                  'max_depth': [3,5,10,20,50,75,100,None],\n",
    "                                  'max_features': ['auto','sqrt'],\n",
    "                                  'min_samples_leaf': [1,2,4,10],\n",
    "                                  'min_samples_split': [2,5,10]}\n",
    "                                  \n",
    "clf_rf_rnd = RandomizedSearchCV(rf, param_distributions = param_grid, n_iter = 100, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf_rnd = clf_rf_rnd.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_rf_rnd,'Random Forest')\"\"\"\n",
    "# funnel approach to find parameters instead of taking days/months\n",
    "# xboost and random forest together?\n",
    "# high performance likely means overfitted :(\n",
    "rf = RandomForestClassifier(random_state = 1)\n",
    "param_grid =  {'n_estimators': [400,450,500,550],\n",
    "               'criterion':['gini','entropy'],\n",
    "                                  'bootstrap': [True],\n",
    "                                  'max_depth': [15, 20, 25],\n",
    "                                  'max_features': ['auto','sqrt', 10],\n",
    "                                  'min_samples_leaf': [2,3],\n",
    "                                  'min_samples_split': [2,3]}\n",
    "                                  \n",
    "clf_rf = GridSearchCV(rf, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf = clf_rf.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_rf,'Random Forest')\n",
    "\n",
    "best_rf = best_clf_rf.best_estimator_.fit(X_train_scaled,y_train)\n",
    "feat_importances = pd.Series(best_rf.feature_importances_, index=X_train_scaled.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "\n",
    "# shows data that is important above which has highest correlation\n",
    "\n",
    "\"\"\"xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 100, 250, 500,1000],\n",
    "    'colsample_bytree': [0.2, 0.5, 0.7, 0.8, 1],\n",
    "    'max_depth': [2, 5, 10, 15, 20, 25, None],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "    'subsample': [0.5,0.6,0.7, 0.8, 0.9],\n",
    "    'learning_rate':[.01,0.1,0.2,0.3,0.5, 0.7, 0.9],\n",
    "    'gamma':[0,.01,.1,1,10,100],\n",
    "    'min_child_weight':[0,.01,0.1,1,10,100],\n",
    "    'sampling_method': ['uniform', 'gradient_based']\n",
    "}\n",
    "\n",
    "#clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "#best_clf_xgb = clf_xgb.fit(X_train_scaled,y_train)\n",
    "#clf_performance(best_clf_xgb,'XGB')\n",
    "clf_xgb_rnd = RandomizedSearchCV(xgb, param_distributions = param_grid, n_iter = 1000, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb_rnd = clf_xgb_rnd.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_xgb_rnd,'XGB')\"\"\"\n",
    "\n",
    "xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [450,500,550],\n",
    "    'colsample_bytree': [0.75,0.8,0.85],\n",
    "    'max_depth': [None],\n",
    "    'reg_alpha': [1],\n",
    "    'reg_lambda': [2, 5, 10],\n",
    "    'subsample': [0.55, 0.6, .65],\n",
    "    'learning_rate':[0.5],\n",
    "    'gamma':[.5,1,2],\n",
    "    'min_child_weight':[0.01],\n",
    "    'sampling_method': ['uniform']\n",
    "}\n",
    "\n",
    "clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb = clf_xgb.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_xgb,'XGB')\n",
    "\n",
    "y_hat_xgb = best_clf_xgb.best_estimator_.predict(X_test_scaled).astype(int)\n",
    "xgb_submission = {'PassengerId': test.PassengerId, 'Survived': y_hat_xgb}\n",
    "submission_xgb = pd.DataFrame(data=xgb_submission)\n",
    "submission_xgb.to_csv('xgb_submission3.csv', index=False)\n",
    "\n",
    "#Model Additional Ensemble Approaches #with tune model \n",
    "\n",
    "best_lr = best_clf_lr.best_estimator_\n",
    "best_knn = best_clf_knn.best_estimator_\n",
    "best_svc = best_clf_svc.best_estimator_\n",
    "best_rf = best_clf_rf.best_estimator_\n",
    "best_xgb = best_clf_xgb.best_estimator_\n",
    "\n",
    "voting_clf_hard = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'hard') \n",
    "voting_clf_soft = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'soft') \n",
    "voting_clf_all = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('lr', best_lr)], voting = 'soft') \n",
    "voting_clf_xgb = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('xgb', best_xgb),('lr', best_lr)], voting = 'soft')\n",
    "\n",
    "print('voting_clf_hard :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5))\n",
    "print('voting_clf_hard mean :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_soft :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5))\n",
    "print('voting_clf_soft mean :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_all :',cross_val_score(voting_clf_all,X_train,y_train,cv=5))\n",
    "print('voting_clf_all mean :',cross_val_score(voting_clf_all,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_xgb :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5))\n",
    "print('voting_clf_xgb mean :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5).mean())\n",
    "\n",
    "\n",
    "# soft voting classifer best performance which means the others that had higher % = overfitted\n",
    "\n",
    "\n",
    "#in a soft voting classifier you can weight some models more than others. I used a grid search to explore different weightings\n",
    "#no new results here\n",
    "params = {'weights' : [[1,1,1],[1,2,1],[1,1,2],[2,1,1],[2,2,1],[1,2,2],[2,1,2]]}\n",
    "\n",
    "vote_weight = GridSearchCV(voting_clf_soft, param_grid = params, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_weight = vote_weight.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_weight,'VC Weights')\n",
    "voting_clf_sub = best_clf_weight.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "#Make Predictions \n",
    "voting_clf_hard.fit(X_train_scaled, y_train)\n",
    "voting_clf_soft.fit(X_train_scaled, y_train)\n",
    "voting_clf_all.fit(X_train_scaled, y_train)\n",
    "voting_clf_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "y_hat_vc_hard = voting_clf_hard.predict(X_test_scaled).astype(int)\n",
    "y_hat_rf = best_rf.predict(X_test_scaled).astype(int)\n",
    "y_hat_vc_soft =  voting_clf_soft.predict(X_test_scaled).astype(int)\n",
    "y_hat_vc_all = voting_clf_all.predict(X_test_scaled).astype(int)\n",
    "y_hat_vc_xgb = voting_clf_xgb.predict(X_test_scaled).astype(int)\n",
    "\n",
    "# fitting and predicting\n",
    "\n",
    "#convert output to dataframe \n",
    "final_data = {'PassengerId': test.PassengerId, 'Survived': y_hat_rf}\n",
    "submission = pd.DataFrame(data=final_data)\n",
    "\n",
    "final_data_2 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_hard}\n",
    "submission_2 = pd.DataFrame(data=final_data_2)\n",
    "\n",
    "final_data_3 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_soft}\n",
    "submission_3 = pd.DataFrame(data=final_data_3)\n",
    "\n",
    "final_data_4 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_all}\n",
    "submission_4 = pd.DataFrame(data=final_data_4)\n",
    "\n",
    "final_data_5 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_xgb}\n",
    "submission_5 = pd.DataFrame(data=final_data_5)\n",
    "\n",
    "final_data_comp = {'PassengerId': test.PassengerId, 'Survived_vc_hard': y_hat_vc_hard, 'Survived_rf': y_hat_rf, 'Survived_vc_soft' : y_hat_vc_soft, 'Survived_vc_all' : y_hat_vc_all,  'Survived_vc_xgb' : y_hat_vc_xgb}\n",
    "comparison = pd.DataFrame(data=final_data_comp)\n",
    "\n",
    "\n",
    "#track differences between outputs \n",
    "comparison['difference_rf_vc_hard'] = comparison.apply(lambda x: 1 if x.Survived_vc_hard != x.Survived_rf else 0, axis =1)\n",
    "comparison['difference_soft_hard'] = comparison.apply(lambda x: 1 if x.Survived_vc_hard != x.Survived_vc_soft else 0, axis =1)\n",
    "comparison['difference_hard_all'] = comparison.apply(lambda x: 1 if x.Survived_vc_all != x.Survived_vc_hard else 0, axis =1)\n",
    "\n",
    "\n",
    "comparison.difference_hard_all.value_counts()\n",
    "\n",
    "#prepare submission files \n",
    "submission.to_csv('submission_rf.csv', index =False)\n",
    "submission_2.to_csv('submission_vc_hard.csv',index=False)\n",
    "submission_3.to_csv('submission_vc_soft.csv', index=False)\n",
    "submission_4.to_csv('submission_vc_all.csv', index=False)\n",
    "submission_5.to_csv('submission_vc_xgb2.csv', index=False)\n",
    "\n",
    "#save and commit\n",
    "# Output folder and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
